{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7R6RnqQu0-P9"
   },
   "outputs": [],
   "source": [
    "prompt = \"During the latest presentation OpenAI\"\n",
    "# prompt = \"During the latest presentation Apple has announced\"\n",
    "model = \"openai-community/gpt2-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hkVKzDegAItu"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15267aa78ea427db948f6fd25fdfc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HomePC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HomePC\\.cache\\huggingface\\hub\\models--openai-community--gpt2-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27112192ea7c4d1e86e7f43ada751451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085e831a34084b34852ce2529158a3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90197ecae6a4149b60b45b095d6ba02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6486d9b7766b4b2b93145575e6527447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a182f935fb354290b7dcfb48751e02be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10e938fc82f402888a3b44fbc9f075d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xUAq3XiAN1z",
    "outputId": "b3c463e5-2cbc-40ee-ec7b-037548c99b24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the latest presentation OpenAI and Facebook have decided to merge into a new AI \"organization,\" based in Paris, with the first job postings already under way. They'll be joining a crowd of roughly 80 start-ups that are developing AI tools and tools for the artificial intelligence.\n",
      "\n",
      "In late February, we reported that while Google has been working on adding more machine learning and deep learning to its platforms, Facebook just announced two big hires: a senior VP of machine learning and data science and\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "generated_texts = text_generator(prompt, max_length=100, truncation=True, num_return_sequences=1)\n",
    "\n",
    "print(generated_texts[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIcEp5Gb4Clo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGcDDPcz1Ln5",
    "outputId": "d463b856-95ce-40dd-92b8-9b2538c89591"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "do_sample=False\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "Robb also said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "\"We're going to be a big deal,\" he said. \"We're going to be the biggest AI project ever.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "do_sample=True\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI researchers and computer scientists explained that the work was not aimed to be done on a large, single system: 'It's not really our goal to do that â€“ at least not at the moment.' They also stressed their approach is to be used in 'the next generation development of AI technologies,' explaining how one of the first steps was to understand that, not in a lab, a machine's goal is to solve a computation problem.\n",
      "\n",
      "In the next few years,\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for do_sample in [\n",
    "    False, # Greedy Search\n",
    "    True   # Multinomial sampling\n",
    "  ]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, do_sample=do_sample, num_beams=1)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"do_sample={do_sample}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo3CC3yk4QmC",
    "outputId": "fa502549-0421-4f86-9599-853c323c0e8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "Robb also said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "\"We're going to be a big deal,\" he said. \"We're going to be the biggest AI project ever.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=2\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO and co-founder Demis Hassabis said that the company is working on a new type of artificial intelligence that will be able to learn from its mistakes.\n",
      "\n",
      "\"We're working on a new type of artificial intelligence that will learn from its mistakes,\" Hassabis said. \"We're not going to be able to predict the future, but we're going to be able to learn from our mistakes.\"\n",
      "\n",
      "Hassabis said that the company is working\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=4\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO and co-founder Demis Hassabis said, \"We are excited to announce that we have reached an agreement with DeepMind to work together on the development of the next generation of artificial intelligence.\"\n",
      "\n",
      "DeepMind is a British artificial intelligence company founded in 2012. It is best known for its work on AlphaGo, a computer program that defeated the world's best Go player, Lee Sedol, at the end of 2016.\n",
      "\n",
      "\"We are excited\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=8\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO and co-founder Demis Hassabis said:\n",
      "\n",
      "\"We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've been working on this for a long time. We've\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beam-search strategy\n",
    "\n",
    "for beams in [1, 2, 4, 8]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, do_sample=False, num_beams=beams)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"num_beams={beams}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K96hVRPC6MUR",
    "outputId": "d7a15983-5a7c-4d89-d251-9fb357909f99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's lead researcher and CEO, Demis Hassabis, detailed the OpenAI mission statement and vision. Hassabis was visibly excited as he told us of the future of AI and how the OpenAI Foundation would use their resources for the benefit of humanity, as well as society at large.\n",
      "\n",
      "\"We're not interested in using artificial intelligence for purposes you don't understand yet\" said Hassabis. \"If we are to be the best we need a set of goals\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=2\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI has been working on an AI system that can understand its environment and make decisions based on the information it has. It's a system that is based on neural networks, which is a type of artificial neural network.\n",
      "\n",
      "Neural networks are a type of artificial neural network that is based on the idea that we can learn from our experience. In other words, we can learn from our mistakes.\n",
      "\n",
      "In order to learn, a neural network has to be trained on\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=4\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI, a team of researchers from the University of Toronto and the University of California, Berkeley, presented a proof-of-concept for a neural network that can beat the world's best Go players.\n",
      "\n",
      "The neural network, called DeepMind's AlphaGo, is trained on millions of games played by top Go players from around the world. AlphaGo is able to play the game at a level of sophistication that has never been seen before.\n",
      "\n",
      "AlphaGo is able\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "num_beams=8\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI CEO Demis Hassabis said:\n",
      "\n",
      "\"We are excited to announce that we are partnering with Google DeepMind to develop the world's first AI system that can beat the world's best human chess players.\"\n",
      "\n",
      "The DeepMind system, named AlphaGo, will be able to beat the world's best human chess players by the end of the year.\n",
      "\n",
      "Google DeepMind CEO Demis Hassabis said:\n",
      "\n",
      "\"We are thrilled to be working with\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beam-search multinomial sampling\n",
    "\n",
    "for beams in [1, 2, 4, 8]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, do_sample=True, num_beams=beams)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"num_beams={beams}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5R7GeD3AUgp",
    "outputId": "8176aaab-28da-4353-b49b-416f624d6eba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "Robb also said that the company is working on a \"biggest AI project ever\" and that it is \"going to be a big deal.\"\n",
      "\n",
      "\"We're going to be a big deal,\" he said. \"We're going to be the biggest AI project ever.\"\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=5\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's director of AI research, Ilya Sutskever, said he was \"not surprised\" by the results.\n",
      "\n",
      "\"I think we are going to see some really interesting things in the next year and a half or two years,\" Sutskever said. \"The big challenge is that we don't know what we're going to do with these things yet. We are still trying to understand them.\"\n",
      "\n",
      "Sutskever said that while the\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=10\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI, the company has shown off its new supercomputer that can beat an average human at the classic video game Go. The company says its machine has been playing Go since the beginning of this year, and it is on the verge of becoming the world's best Go player. The supercomputer is a hybrid machine with a processor made of silicon and a GPU made up of Nvidia's GPU technology. The GPU is capable of processing hundreds of gigabytes per second.\n",
      "\n",
      "Open\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=50\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's director of research Michael Malhotra (pictured) says it could be an ideal place to host a \"super AI\" - a machine that can do calculations without the aid of external data.\n",
      "\n",
      "Advertisement\n",
      "\n",
      "While such a machine would probably need vast amounts of processing power to process all the possible outcomes of a game of Go - a complex strategy game with two players (one in each corner of a square or diagonal) that is played every five moves - an\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=100\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI, a team of AI researchers from the University of Oxford recently used a computer model called DeepDream to create the most realistic character ever imagined by human beings: the Hulk. The new study, published recently in the journal PLOS ONE, is a great example of the way we should be using artificial intelligence to improve people's lives.\n",
      "\n",
      "DeepDream is a computer rendering software suite that's already powering some impressive work like DeepFace, a deep learning-based face recognition\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "top_k=500\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI co-founder Yann LeCun said humans had once been a key component of the universe but now that an artificial intelligence has taken it over the human-ness has gone.\n",
      "\n",
      "\"Now we're at Mars, no one seems to care anymore. You can go to Kanyakumari and be the world's only inhabitants, you'll die a long, long time ago. Our society began as people who wanted to get lunch and live against those who\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change the top-k parameter\n",
    "\n",
    "for k in [1, 5, 10, 50, 100, 500]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, top_k=k)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"top_k={k}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXOuaxe0RJwf",
    "outputId": "54502e72-3a95-4877-8f82-17b01e00ed0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=0.1\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's CEO, John Robb, said that the company is \"working on a new AI platform that will allow us to build a new generation of AI systems that will be able to do things that are not possible today.\"\n",
      "\n",
      "Robb also said that the company is working on a new AI platform that will allow it to build a new generation of AI systems that will be able to do things that are not possible today.\n",
      "\n",
      "\"We're building a new AI platform\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=1.0\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI's DeepQA (DQA, pronounced \"Darth Quay\") found itself facing off with researchers from Google DeepMind and IBM. The two researchers were using a deep neural network to teach the computer to solve simple classification tasks as well as one of the toughest AI challenges. The task was to classify the content of random samples provided by the media.\n",
      "\n",
      "Here's what the network was tasked with:\n",
      "\n",
      "To give you a sense of what I mean\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=2.0\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI.Net in London about their AI technology Deep Learning systems is able to accomplish tasks more easily than humans using these networks of networks of super intelligent deep learning computing systems known as artificial neural networks.\n",
      "\n",
      "\n",
      "We, the crowd can now now make comments using OpenAI.NET platform after playing this video: Click the arrow.\n",
      "\n",
      "\n",
      "For better view view at open-ai-node page, visit open-ai-tow node of Github.\n",
      "\n",
      "Talks and\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "Parameters:\n",
      "-----------------------------------\n",
      "temperature=3.0\n",
      "-----------------------------------\n",
      "Generation:\n",
      "-----------------------------------\n",
      "During the latest presentation OpenAI leader, Dominik Baumgardner, noted his mission, \"to help solve one or few simple hard problem by developing deep, AI and optimization platform\". His goal sounds much, rather easy; a common reason AI is challenging in high profile industry related fields, or that is usually discussed as difficult-difficulty, at those times (which can seem ridiculous considering all you just hear from companies claiming they are on to them). From a purely human point as in \"\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change temperature\n",
    "\n",
    "for temp in [0.1, 1.0, 2.0, 3.0]:\n",
    "  generated_texts = text_generator(prompt, max_length=100, num_return_sequences=1, temperature=temp)\n",
    "\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Parameters:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(f\"temperature={temp}\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"Generation:\")\n",
    "  print(\"-----------------------------------\")\n",
    "  print(generated_texts[0]['generated_text'])\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUiu5ZdT9ArW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
