{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z2ea-5SaF59N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Use CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9CRij9k1GDlM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DSc0ludHGE1o"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "text = Path('../data/tiny-shakespeare.txt').read_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7-9Nk7OoGGHc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[0:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qg-yHMXPGHYq"
      },
      "outputs": [],
      "source": [
        "class CharTokenizer:\n",
        "  def __init__(self, vocabulary):\n",
        "    self.token_id_for_char = {char: token_id for token_id, char in enumerate(vocabulary)}\n",
        "    self.char_for_token_id = {token_id: char for token_id, char in enumerate(vocabulary)}\n",
        "\n",
        "  @staticmethod\n",
        "  def train_from_text(text):\n",
        "    vocabulary = set(text)\n",
        "    return CharTokenizer(sorted(list(vocabulary)))\n",
        "\n",
        "  def encode(self, text):\n",
        "    token_ids = []\n",
        "    for char in text:\n",
        "      token_ids.append(self.token_id_for_char[char])\n",
        "    return torch.tensor(token_ids, dtype=torch.long)\n",
        "\n",
        "  def decode(self, token_ids):\n",
        "    chars = []\n",
        "    for token_id in token_ids.tolist():\n",
        "      chars.append(self.char_for_token_id[token_id])\n",
        "    return ''.join(chars)\n",
        "\n",
        "  def vocabulary_size(self):\n",
        "    return len(self.token_id_for_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pAYBFds4GNAb"
      },
      "outputs": [],
      "source": [
        "tokenizer = CharTokenizer.train_from_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LKq-R9xvJ3RX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([20, 43, 50, 50, 53,  1, 61, 53, 56, 50, 42])\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(\"Hello world\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tWpR_hr9GOKs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello world\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(tokenizer.encode(\"Hello world\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3a7qPM-mGPur"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocabulary_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UbtX7_JtHFXL"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(depth=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2I3m9KI6HM-S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '\\n',\n",
            " 1: ' ',\n",
            " 2: '!',\n",
            " 3: '$',\n",
            " 4: '&',\n",
            " 5: \"'\",\n",
            " 6: ',',\n",
            " 7: '-',\n",
            " 8: '.',\n",
            " 9: '3',\n",
            " 10: ':',\n",
            " 11: ';',\n",
            " 12: '?',\n",
            " 13: 'A',\n",
            " 14: 'B',\n",
            " 15: 'C',\n",
            " 16: 'D',\n",
            " 17: 'E',\n",
            " 18: 'F',\n",
            " 19: 'G',\n",
            " 20: 'H',\n",
            " 21: 'I',\n",
            " 22: 'J',\n",
            " 23: 'K',\n",
            " 24: 'L',\n",
            " 25: 'M',\n",
            " 26: 'N',\n",
            " 27: 'O',\n",
            " 28: 'P',\n",
            " 29: 'Q',\n",
            " 30: 'R',\n",
            " 31: 'S',\n",
            " 32: 'T',\n",
            " 33: 'U',\n",
            " 34: 'V',\n",
            " 35: 'W',\n",
            " 36: 'X',\n",
            " 37: 'Y',\n",
            " 38: 'Z',\n",
            " 39: 'a',\n",
            " 40: 'b',\n",
            " 41: 'c',\n",
            " 42: 'd',\n",
            " 43: 'e',\n",
            " 44: 'f',\n",
            " 45: 'g',\n",
            " 46: 'h',\n",
            " 47: 'i',\n",
            " 48: 'j',\n",
            " 49: 'k',\n",
            " 50: 'l',\n",
            " 51: 'm',\n",
            " 52: 'n',\n",
            " 53: 'o',\n",
            " 54: 'p',\n",
            " 55: 'q',\n",
            " 56: 'r',\n",
            " 57: 's',\n",
            " 58: 't',\n",
            " 59: 'u',\n",
            " 60: 'v',\n",
            " 61: 'w',\n",
            " 62: 'x',\n",
            " 63: 'y',\n",
            " 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "pp.pprint(tokenizer.char_for_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "olX9rHjxHQih"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0,\n",
            " ' ': 1,\n",
            " '!': 2,\n",
            " '$': 3,\n",
            " '&': 4,\n",
            " \"'\": 5,\n",
            " ',': 6,\n",
            " '-': 7,\n",
            " '.': 8,\n",
            " '3': 9,\n",
            " ':': 10,\n",
            " ';': 11,\n",
            " '?': 12,\n",
            " 'A': 13,\n",
            " 'B': 14,\n",
            " 'C': 15,\n",
            " 'D': 16,\n",
            " 'E': 17,\n",
            " 'F': 18,\n",
            " 'G': 19,\n",
            " 'H': 20,\n",
            " 'I': 21,\n",
            " 'J': 22,\n",
            " 'K': 23,\n",
            " 'L': 24,\n",
            " 'M': 25,\n",
            " 'N': 26,\n",
            " 'O': 27,\n",
            " 'P': 28,\n",
            " 'Q': 29,\n",
            " 'R': 30,\n",
            " 'S': 31,\n",
            " 'T': 32,\n",
            " 'U': 33,\n",
            " 'V': 34,\n",
            " 'W': 35,\n",
            " 'X': 36,\n",
            " 'Y': 37,\n",
            " 'Z': 38,\n",
            " 'a': 39,\n",
            " 'b': 40,\n",
            " 'c': 41,\n",
            " 'd': 42,\n",
            " 'e': 43,\n",
            " 'f': 44,\n",
            " 'g': 45,\n",
            " 'h': 46,\n",
            " 'i': 47,\n",
            " 'j': 48,\n",
            " 'k': 49,\n",
            " 'l': 50,\n",
            " 'm': 51,\n",
            " 'n': 52,\n",
            " 'o': 53,\n",
            " 'p': 54,\n",
            " 'q': 55,\n",
            " 'r': 56,\n",
            " 's': 57,\n",
            " 't': 58,\n",
            " 'u': 59,\n",
            " 'v': 60,\n",
            " 'w': 61,\n",
            " 'x': 62,\n",
            " 'y': 63,\n",
            " 'z': 64}\n"
          ]
        }
      ],
      "source": [
        "pp.pprint(tokenizer.token_id_for_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLnPsybaHTew"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
